\documentclass[journal]{IEEEtran}
\newcommand\tab[1][1cm]{\hspace*{#1}}

\usepackage{xr,ulem}
\usepackage{amssymb,amsmath}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{times}
\usepackage{url,soul}
%\usepackage{algorithm}
\usepackage{algorithm,algpseudocode}

%\usepackage{algorithmic}
\usepackage[latin9]{inputenc}
\usepackage{color}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{csquotes}
\usepackage{flushend}
\usepackage{algolyx}
\usepackage[colorinlistoftodos]{todonotes}
\soulregister\cite7
\begin{document}

\title{Characterization of Indicators for Adaptive Human-Swarm Interaction}

\author{\IEEEauthorblockN{Aya Hussein, Leo Ghignone, Tung Nguyen, Nima Salimi, Hung Nguyen, Min Wang, and~Hussein A. Abbass}
\IEEEauthorblockA{\textit{School of Engineering and Information Technology} \\
\textit{University of New South Wales}\\
Canberra, Australia}}
%\thanks{School of Engineering and Information Technology, 
%              The University of New South Wales, 
%              Northcott Drive, Campbell, 
%              Canberra, ACT, Australia 2600.  
%              Tel.: +61 2 62688158.
%              a.hussein@student.adfa.edu.au
%}
\markboth{IEEE Transactions on Human-Machine Systems,~Vol.~xx, No.~xx, Month,~YEAR}%
{Hussein et al.}
\maketitle
\begin{abstract}
Swarm systems consist of large numbers of robots that collaborate autonomously. 
With an appropriate level of human control, swarm systems could be applied in a variety of contexts ranging from urban search and rescue situations to Cyber defence. 
However, the successful deployment of the swarm in such applications is conditioned on the effective coupling of the human and the swarm. 
While adaptive autonomy promised to provide enhanced performance in human-machine interaction, its implementation within human-swarm interaction has to consider distinct factors. 
This paper brings disparate pieces of the ground work in this research area together to review this multidisciplinary literature. 
We propose a framework that maps out the primitive state indicators needed for  adaptive human-swarm systems.
\end{abstract}

\begin{IEEEkeywords}
Adaptive autonomy \and Human Swarm Interaction \and Mission Performance Indicators \and Interaction Indicators \and Complexity Indicators \and Automation Indicators \and Human Cognitive States Assessment
\end{IEEEkeywords}

\section{Introduction}
The recent technological advancements enabled the realisation of swarm systems that can include large numbers of robots. 
Using local communication and distributed coordination, these robots can achieve complex global behaviours that can be utilised in a wide range of applications. 
Yet, fully autonomous swarms that are free of human supervision are hard to realise due to technological and ethical impediments. 
Technologically, although artificial intelligence could beat human intelligence in a number of applications, it is unexpected to outperform general human intelligence in the near future~\cite{should}. 

The success of fully autonomous swarm operations in dynamic and complex environments, and in the absence of human oversight remains as a vision for a reasonably distant future.  
The challenges are not purely technological but extend to legal and moral challenges as well. 
Ethically, the full autonomy can be undesirable due to the responsibility and accountability issues as discussed in~\cite{should}. 
Human-Swarm systems will remain as the most feasible path, at least for the foreseeable future, to adopt swarm systems in realistic environments. 
Effective and efficient Human-Swarm Interactions (HSI) call for intelligent agents capable of adaptively and dynamically allocating the functions required to performed the mission between the humans and the swarm. 

Adaptive autonomy~\cite{aiding,AdaptiveHA,triggers} has been gaining increasing interest in the literature of human-automation interaction (HAI) and human-robot interaction (HRI) as a flexible autonomy scheme that acknowledges the dynamic and uncertain nature of the interaction. 
In adaptive autonomy, the functions required to achieve a mission are identified in advance. 
For example, if the mission is to drive a vehicle from its current location to a goal, the functions to achieve this mission could include: (a) an environment monitoring function, (b) current car-state estimation function, (c) a hazard detection function, (d) a rout planning function, (e) a vehicle dynamic function, and (f) a vehicle steering function.

An artificial intelligence (AI) agent is responsible of the adaptive logic required to dynamically allocate these functions to the human and the autonomous vehicle(s) based on the current requirements of the task and the states and capabilities of its potential performers (humans and machines). 
Adaptive autonomy has demonstrated its ability to enhance the performance of the overall human-machine interaction and mission~\cite{teaming}. 
This enhancement is attributed to its ability to reconcile conflicting requirements within the interaction (e.g make best use of the automation but ensure the human doesn\textquoteright t lose their situational awareness or level of engagement). 
The working of adaptive autonomy can be described by two questions: \textit{when} and \textit{how}. 
The \emph{when} question is concerned with evaluating the current state of the overall system-of-systems to determine whether an adaptation is needed. 
The \emph{how} question is concerned with generating new task assignments and accordingly user interface changes. 
Such a requirement comes with a few challenges including how to dynamically adjust the level of autonomy of different players, how to strengthen mutual trust, and what mechanisms are required to facilitate situational awareness (SA) of the players~\cite{chen2014human}.

The aim of this paper is to identify and fuse together different categories of indicators needed for adaptive autonomy in the area of human-swarm interaction (HSI). 
The adaptive logic AI agent needs to form its own contextual awareness to be able to decide when adaptation is needed.
Such contextual awareness requires continuous assessment of the states of different components in the overall system.
Therefore, the main focus of the paper is placed on the indicators that will enable the AI agent to answer the \textit{when} question. 

In section~\ref{Autonomy} we discuss some weaknesses of fixed autonomy and human-based flexible autonomy that make agent-based adaptive autonomy superior to them. 
Then, in section~\ref{framework}, we present a framework for adaptive autonomy that facilitates the realisation of effective HSI. 
In section \ref{indicators}, we distil five groups of indicators that are necessary for adaptive agent to operate properly. 
Details of these classes of indicators are then given in sections \ref{performance} to \ref{complexity}. 
In section \ref{implications}, we present the \textit{MICAH} framework that combines the five types of indicators and discuss the implications of different outcomes of state assessment. 
The conclusion and future work are finally given in \ref{conclusion}.

\section{Autonomy in HSI}\label{Autonomy}
In HSI, humans and swarms need to act as a team to optimise common mission objectives. 
The human and the swarm are assigned complementary roles with the aim of combining their skills efficiently and in a manner that achieves mission goals. 
Fixing the level of autonomy within the swarm produces a rigid system in which the human can experience undesirable levels of workload. 
This applies regardless of the level of autonomy the swarm exhibits. 
If the level of autonomy is low, the human carries most of the load with the end result of finding the human overloaded. 
On the contrary, if the swarm\textquoteright s level of autonomy is high, the human could become underloaded. 
Both situations are undesirable as they can lead to difficulties in sustaining human situational awareness (SA) and to a drop in human performance~\cite{endsley1997} and engagement level~\cite{endsley2017}. 
On the long term, fixed autonomy has been criticised for the associated skill degradation~\cite{aiding}.

To realise effective interaction, the humans and the swarm need to coordinate their actions throughout the mission to maintain acceptable levels of workload while ensuring the tasks are performed effectively. 
This coordination can be assigned to the human or to a coordinating agent. 
Designating the human to the coordination can be time consuming and potentially unsafe in situations where the human operator is naturally overloaded because of task demands~\cite{chen2014human}. 
Besides, task delegation to a human\textquoteright s hands is subjective and depends on human factors that reach beyond the realm of workload (e.g. emotional stress). 
Some operators would place more constraints on the automation at the expense of time, while others might place less constraints on automation at the expense that the automation\textquoteright s behaviour can diverge from the operator\textquoteright s intent~\cite{miller2005playbook}. 

To overcome the aforementioned challenges, the coordination can be performed by an adaptive logic AI agent that sits at the interface between the human and the swarm to facilitate the coordination by monitoring and managing the states of different entities in the system. The agent decides on whether the level of autonomy should be risen or lowered based on the state of the mission as assessed by some input indicators. The accurate assessment of the mission is important to avoid sudden changes that can be inappropriate or annoying for the human~\cite{teaming}. In a taxonomy of triggers for adaptive autonomy, Feigh et al.~\cite{triggers} proposed  five categories: operator, system, environment, task/mission, and spatio-temporal triggers. Their work offered a high level overview of the adaptive agent without delving into the indicators required for each type of trigger. Moreover, a swarm context is a decentralized context. Designing the adaptive agent for decentralized applications is a research area at its infancy. We will fill this gap by distilling from the literature the list of indicators that could provide state assessment of different components in HSI. We study how the state of each component can be quantified using synthesized indicators from the literature.

\section{Framework for Adaptive Autonomy in HSI} \label{framework}

Despite the increasing interests of deploying swarms in real-life applications, humans will remain a critical part of the autonomous control loop due to legal/ethical concerns and practical considerations; at least for  foreseeable future~\cite{nothwang2016human}. A framework for adaptive autonomy in HSI brings together both humans and swarm agents to optimise the performance of the overall system. The framework aims to achieve seamless and adaptive interaction between humans and the swarm to maximize mission objectives. To accomplish this goal, a significant number of state indicators is needed for the accurate evaluation of the state of different components in the overall system.  

Conventional adaptive systems trigger adaptation processes in specific situations or for particular tasks~\cite{triggers}. The system resumes the default setting once the trigger is no longer active. However, as the situation and context evolve, the once adequate adaptation strategy applied by conventional adaptive systems might become inadequate~\cite{fuchs2017towards}. To address this problem, dynamic adaptations based on a diverse set of indicators are required. However, these indicators are normally spread across different fields. For example, to assess the human mental states, the indicators would come from cognitive psychology, behavioural psychology and human factors. Meanwhile, to assess the success of an autonomous decision, the indicators would come from system engineering, control theory, and AI.

In this paper, we synthesize from this wide interdisciplinary literature those groups of indicators required to provide state assessment for the adaptive logic AI agent. A conceptual diagram of the framework is presented in Fig.~\ref{fig:framework} along with a pseudocode in Alg.~\ref{algo} for the adaptive logic AI agent. 

The adaptation strategy of the adaptive logic AI agent can be seen as two high-level steps: a monitoring and state assessment step followed by an adaptation step. The adaptive agent could take many forms including a rule-based system, neural network, or other forms of symbolic and non-symbolic approaches. Below is an example of how the indicators could support the adaptive logic AI agent based on real implementations from our previous work~\cite{AdaptiveHA,harvey2018assessing,abbass2014computational}.

Psycho-physiological sensors collect the human operator's cognitive information, which are then translated into a series of human states indicators, including workload, fatigue and focused attention indicators. Integrated with information of the current task and system states, these human states indicators are used by the adaptive logic AI agent to decide on whether to adapt or not. For example, high workload and fatigue might compromise the human operator's performance so the system might raise the autonomy level of the swarm or a subgroup of the swarm to allow the human operator to only focus on the most critical task. In another case, the lack of a human\textquoteright s cognitive attention might cause serious consequences, especially in emergency situations. Therefore, the system might lower the autonomy level of the swarm or a subgroup of the swarm and update interaction modes and visualisation to counterbalance the human states within a safe range. 

\begin{figure*}[ht!]
\centering
\includegraphics[width=0.95\textwidth]{./Figures/AASystem}
\caption{Framework for adaptive autonomy in HSI}
\centering \label{fig:framework}
\end{figure*}

\begin{algorithm*}
\centering
\begin{algorithmic}%[1]
\While{Not end of mission}

\State $A = Performance\_indicators \leftarrow Monitor\_Performance()$

\State $B = Human\_indicators \leftarrow Assess\_Human\_State()$

\State $C = Swarm\_indicators \leftarrow Assess\_Automation\_Indicators()$

\State $D = Complexity\_indicators \leftarrow Assess\_Task\_Complexity()$

\State $E = Interaction\_indicators \leftarrow Assess\_Interaction() $

\State $ Triger\_adaptation \leftarrow Is\_Adaptation\_Needed(A,B,C,D,E)$
\If {$Triger\_adaptation$}

\State $New\_task\_assignment = Reallocate\_Functions(B,C,D,E)$

\State$Interface\_Changes= Adapt\_Interface(B,D,New\_task\_assignment)$

\State $Apply\_Changes(New\_task\_assignment, Interface\_changes)$

\EndIf
\EndWhile
\end{algorithmic}
\caption{A pseudocode for the adaptive logic AI agent using indicators from the proposed framework.}
\label{algo}
\end{algorithm*}

\section{Indicators for Adaptive HSI Systems}\label{indicators}
In this section, we will first use a scenario to explain adaptive autonomy in an HSI context then unfold the components and requirements for a good set of indicators.

\subsection{Human-Swarm Scenario} \label{scenario}

Consider a search-and-rescue (SAR) scenario where victims are spatially spread in an urban area after an earthquake. An uninhabited aerial vehicle (UAV) remotely operated by a human pilot is used to guide a swarm of uninhabited ground vehicles (UGVs). Each UGV has a camera and a Laser Imaging, Detection And Ranging (LIDAR) sensor. The sensors on the UGVs are used to detect victims and retrieve them to drop-off/collection locations to offer them with first aid services before transporting them to a hospital. The mission objective is to maximise the number of victims retrieved within the allowed time frame.  

The victims may move to other locations as they search for rescuers or appear and disappear at any time due to noise in the sensors. The human UAV operator has better sensing technologies in its UAV and thus is better able to assess the presence or absence of victims in an area. However, the nature of the UAV does not allow it to access areas that the UGVs can. The UGVs swarm is able to get closer to victims to better identify them. The swarm will always be attracted to the closest victim, but the human may be able to suggest better routes by considering the general disposition of victims and their future movements. Nevertheless, latency in the communication between the UAV and UGVs could cause delays that reduce the worthiness of information. Human's control of the system, therefore, could lead to a sub-optimal behaviour when over-use causes network overload and an increase on human workload could result in an increase in human error. 

In summary, high levels of autonomy throughout the mission are undesirable as the swarm can make errors in the identification of victims and may act on biased local information alone. Meanwhile, low levels of autonomy will increase humans' workload, causing an increase in human errors and an increase in network's load. The role of adaptive autonomy in this scenario is to balance the load on the human and the autonomous system to ensure that the overall system of systems acts efficiently and effectively.

\subsection{Different Requirements}
Different components within the interaction can have unique requirements for autonomy adaptation. To begin with, the success of the mission is the ultimate goal of the interaction and the primary purpose for forming a team of humans and the swarm. Therefore, mission performance indicators are crucial to ensure successful mission. In the scenario above, a high rate of collection is a signal that the current distribution of responsibilities between the human operators and the swarm of UGVs is appropriate. On the other hand, a low rate of victim collection is a signal that some fix is needed, but it doesn\textquoteright t provide, on its own, sufficient information on the source of the problem, whether it lies in the swarm, the human, or their interaction.

Swarm automation indicators could offer information on how well the swarm is performing. For instance, if the swarm is found to be in a chaotic state, breaking apart or with a high number of collisions, it is an indication that the swarm is one of the contributor to the low performance. But, whether more or less human intervention is needed to return the swarm to a stable state is a question whose answer needs information from the interaction indicators. 

Indicators of the effectiveness of the interaction between human and swarm tells us whether the increase in human involvement in one task causes an increase in the rate of victim collection. If so, then giving less autonomy to the swarm might be considered to improve the results. Yet, such a setting can overwhelm the human. Therefore, we need to keep an eye on the human cognitive states to make sure they stay within the desirable range.  Otherwise, if the human continues to be overloaded for a prolonged amount of time, the performance of the team risk degradation unless some amount of work is lifted from the human. Then, which task to offload from the human is not a trivial question. It has to be based on the understanding of how each task is contributing to human workload and the potential effects of different task assignments on the experience workload. Fortunately, this information can be obtained from the analysis of task complexity using task complexity indicators. 

Following this discussion, we contend that these five categories or components (mission performance, swarm automation, interaction, human cognitive states, task complexity) are of crucial importance to the adaptive agent. Thus, the corresponding classes of indicators are considered for state assessment within our framework. In the next sections, we discuss each of these classes of indicators.

\section{Mission Performance}\label{performance}
Automation equips an automaton with functions to process and/or execute tasks. The level of automation, therefore, represents an agent\textquoteright s capacity to perform a task, while autonomy expresses \enquote{the \textit{freedom} to make decisions}~\cite{abbass2016trusted} afforded by the opportunity that exists to allow an agent to act. Autonomy carries negative risks when the capacity of an agent, that is, automation, is conceptually less than the capacity required to perform a task given an opportunity within a mission. %Human-machine teaming (HMT) brings humans as biological autonomous systems with autonomous machines to work together to optimize a mission\textquoteright s objectives.

The primary aim of the team composed of human and the swarm is to perform the mission successfully, which calls for indicators to allow the team to monitor progress towards mission\textquoteright s objective(s) in order to take corrective actions and/or adapt accordingly. We distinguish between how to measure effectiveness (achieving mission success) and efficiency (achieving the success using minimum resources/time) of the system performance in HSI.  While mission effectiveness indicators are success indicators for the HSI in achieving mission objectives, mission efficiency is more about how competent the human and the swarm are in achieving these objectives.

Details of mission effectiveness and efficiency metrics are discussed in the following subsections.
% Nevertheless, one can see a strong relationship between effectiveness (ET), efficiency (EC), and resource usage (RU), which we attempt to depict in Equation~\ref{eqMission-Relationship} as follows:
% \todo[inline, color=green!40]{Do we need RU? and wht is the meaning of bigotimes }
% \begin{equation}\label{eqMission-Relationship}
%     \textit{$\uparrow E_{max}$ = $\uparrow$  ET  $\bigotimes \uparrow$  EC   $\bigotimes \downarrow $ RU}
% \end{equation}
% where $E_{max}$ is a expectation of achieving maximum performance in HSI.

\subsection{Mission Effectiveness}
Mission effectiveness is considered as a factor of assessing how well a HSI achieves the mission. Olsen and Goodrich~\cite{olsen2003metrics} emphasise the importance of verifying mission effectiveness in designing an appropriate model of HSI. In the literature, there are various metrics chosen to measure mission effectiveness. Generally, the overall goal is to maximize mission effectiveness, but the exact measurements chosen would depend on the nature of the mission. Below, we give examples of metrics proposed in literature to measure the effectiveness of typical HSI missions, namely SAR and navigation. %For example, error measurements are used to guide a system to minimize damage, while coverage measurements are used to calculate how much an area has been explored. 

Under the umbrella of the National Institute of Standard and Technology (NIST), Jacoff et al.~\cite{jacoff2001reference,jacoff2001standard} proposed a list of quantitative and qualitative metrics to evaluate the performance of a team of humans and a group of autonomous ground vehicles in an SAR mission. These metrics were the number of localized victims, the number of found obstacles, the number of packages supplied to victims (such as first aids, radios, or food and water), and quality of communication with humans. These metrics add reward points to the overall measure of mission effectiveness. Points are lost when the team causes damage to the surrounding environment, victims, or themselves. The three primary metrics used for effectiveness were: recovery rate representing percentage of victims localized versus number within the debris; accurate rate being the percentage between the number of correctly localized victims and the total number of localized victims; and the total damage relating to victims and the environment.

In navigation missions, Steinfeld et al.~\cite{steinfeld2006common} introduced five key measures of effectiveness: percentage of navigation tasks successfully completed, area coverage, deviation from a planned route, obstacles that were successfully avoided, and obstacles that were not avoided, but could be overcome.

Focusing on SAR missions with a time-critical requirement, Crandall and Cummings~\cite{crandall2007identifying} conducted an HSI scenario where the mission effectiveness was evaluated through two measurements: the number of objects collected (OC) and the number of robots remaining (RR) at the end of the mission. 
%The score is used to evaluate whether mission effectiveness is high or not as described in Equation~\ref{eqMission-Crandall}:
% \todo[inline, color=green!40]{??}
% \begin{equation}\label{eqMission-Crandall}
%     \textit{Score} = OC-RR
% \end{equation}

Chien et al.~\cite{chien2012scheduling} propose a list of measurements used to evaluate the effectiveness of the interaction between humans and a group of autonomous robots. These measurements are: the number of victims rescued, the distance travelled and the percentage of area coverage.

Harriott et al.~\cite{harriott2014biologically} %and Manning et al.~\cite{manning2015heuristic} 
introduced metrics to monitor the progression of a mission: area coverage and mode error or total damage. They also proposed a metric for resource collection to represent the progression of a foraging mission. They used Equation~\ref{eqMission-Resourcedepletion}, to measure resource collection as follows:

\begin{equation}\label{eqMission-Resourcedepletion}
    \textit{$S_i(t+1)$ = $S_i(t)$ - $N\times e$}
\end{equation}
, such that resource (i) with size (S) is collected through time steps (t).  $e > 0$ represents the amount of resource to be reduced by an agent, and $N$ is the number of agents within $r_e$ meters from the resource location. Low values for $S_i(t+1)$ result from high rates of resource collection, which corresponds to higher mission effectiveness. 

\subsection{Mission Efficiency}
Mission efficiency aims to minimize usage of resources and time without compromising mission success. 

In SAR missions, Jacoff et al.~\cite{jacoff2001reference,jacoff2001standard} used time to complete as a measure of mission efficiency, such that if the time stayed within some limits, then the team would receive extra points; otherwise it would lose points.

Steinfeld et al.~\cite{steinfeld2006common} introduced three efficiency metrics about time as follows: mission completion time , operator time, and average time for extracting obstacles or average time to complete all subtasks. Chien et al.~\cite{chien2012scheduling} introduced the \enquote{event timeline} concept to also indicate the operator\textquoteright s time, in a similar manner to the operation loading~\cite{jacoff2001reference}.

%Resource depletion as used by Harriott  et al.~\cite{harriott2014biologically} that was discussed for mission effectiveness could equally be used for mission efficiency.

Following this discussion, it is evident that many metrics can be used for both effectiveness and efficiency. The difference lies in the definition of mission objectives and the scarcity of the resources. For instance, in an SAR mission, swarm power consumption can affect the effectiveness of the mission if the battery life of the robots is limited such that robots will not  be able to progress after depleting the power. On the other hand, if the power is a non-scarce resource, then power consumption becomes a metric of efficiency relating to minimising the cost. 

\subsection{General Metrics for Mission Performance}
We conclude this section with a set of common metrics, which can be used in various missions, for evaluating the mission performance.
\begin{itemize}
\item Mission Effectiveness Metrics  
\begin{itemize}
\item Percentage of mission completion;
\item Total damage to the human-swarm system (e.g. number of robots damaged);
\item Mission constraints satisfaction
\item Number of undesired states (e.g. obstacles encountered);
\end{itemize}

\item Mission Efficiency Metrics
\begin{itemize}
\item Total completion time;
\item Time for individual subtasks completion;
\item Resource depletion (e.g. power consumption)
\end{itemize}

\end{itemize}

The indicators introduced above are distilled to form the fusion sub-tree presented in Fig.~\ref{fig:tree_mission_objs}, where both measures of effectiveness and measures of efficiency form the two dimensions to measure \textit{Mission Performance}.

\begin{figure*}[pt]
\centering
\includegraphics[width=0.9\textwidth]{./Figures/tree_mission}
\caption{Examples of useful indicators for Mission success.}
\label{fig:tree_mission_objs}
\end{figure*}

\section{Swarm Automation Level}

The automation level of the swarm represents its capacity at a certain moment of time to complete its task without a need for human intervention. Finding effective metrics for the analysis of a swarm, as stated by Kolling et al.~\cite{kolling2016human}, is still an open research problem. We will use the concepts of \textit{Human Dependence} and \textit{Neglect Benevolence} to combine and summarize the various metrics presence in the literature.

\textit{Human Dependence} is a renaming of what Crandall et al.~\cite{crandall2005validating} called \textit{Neglect Tolerance} in their work, which is slightly different from the common definition of Neglect Tolerance in the literature~\cite{olsen2003metrics,crandall2007identifying}. In order to preserve consistency both within this paper and with the literature, we will use \textit{Human Dependence} as a measure of how much a robot is in immediate need of human intervention.

\textit{Human Dependence} corresponds to the composition of two different sub-metrics: \textit{Neglect Tolerance}, which describes how the performance of the robot decreases while it is being neglected, and \textit{Interaction Efficiency}, which describes how the performance of the robot increases when a human starts interacting with it after a period of neglect. Both of these measurements are correlated to the level of automation of the robot (e.g. a high automation robot will not suffer much from being neglected, but could also experience reduced gains from human interaction)
 , the complexity of the current situation, and previous history of interaction/neglect. The performance of a robot can then be described by the following equation:
\begin{equation}
  P(\pi,C,t)=
  \begin{cases}
    P_I(\pi,C,t_\textit{on},T_N), & \text{if interacting}\\
    P_N(\pi,C,t_\textit{off}),    & \text{otherwise}
  \end{cases}
\end{equation}
where $P$ denotes performance, $P_I$ denotes performance while the human is interacting with the robot, $P_N$ denotes  performance while the human is neglecting the robot, $\pi$ denotes current level of autonomy, $C$ denotes the complexity of the situation, $t_\textit{on}$ and $t_\textit{off}$ denote the times since the start of the current interaction/neglect, and $T_N$ denote the time the robot had been neglected before the start of the current interaction.

Some useful metrics to estimate swarm's \textit{Situation Complexity} $C$ can be found in Manning et al.~\cite{manning2015heuristic} and they are listed below: 

\begin{itemize}
\item Cohesion: Evaluating the connectivity level of swarm.
\item Diffusion: Assessing the convergence and separation of swarm members.
\item Centre of Gravity: Aiming to minimize the distance from the central point to other points in the spatial distribution of the swarm.
\item Directional Accuracy: Measuring the accuracy between the swarm\textquoteright s movement and the desired travelling path.
\item Flock Thickness: Measuring the swarm\textquoteright s density.
\item Resource Depletion: Qualifying the irreversible consumption of limited resources by swarm members.
\item Swarm Health: Evaluating the current status of the swarm.
\end{itemize}

In particular, \textit{Swarm Health} is an important aspect for determining the difficulties faced by the swarm, and it can be decomposed following the analysis by Hariott et al.~\cite{harriott2014biologically} into the following sub-components:

\begin{itemize}
\item Number of Stragglers: studied by Parrish et al.~\cite{parrish2002self} as the number of fish of a school distant at least 5 body lengths from any other fish. This can reflect difficulties encountered by the swarm caused by obstacles in the environment or conflicting commands.

\item Subgroups number and size: as explained by Navarro and Matia~\cite{navarro2009proposal}, the number and size of subgroups can vary due to obstacles or as a way to perform the task more efficiently. In a swarm, subgroups can be identified and measured using clustering algorithms.

\item Collision Count: also by Parrish et al.~\cite{parrish2002self}, this is the number of collisions between members of the swarm. If a collision avoidance system is in place, this could be the number of times this system had to intervene.
\end{itemize}

The other factor that is relevant to automation in an HSI system is \textit{Neglect Benevolence}, which is a consequence of the fact that a swarm needs some time to stabilize after receiving an instruction before being ready to receive further instructions. In Nagavalli et al.~\cite{nagavalli2014neglect}, this concept is formally defined and analyzed, leading to a complex algorithm for finding the optimal intervention time that requires computing the convergence time for the swarm with input given at different times. In practice, it may be possible to estimate the current value of \textit{Neglect Benevolence} empirically utilizing the time since the last human intervention and the factors that Walker et al.~\cite{walker2012investigating} reported to be influenced by \textit{Neglect Benevolence}; these are: \textit{Directional Accuracy} and \textit{Cohesion}. These two factors are both among those already used to compute \textit{Situation Complexity}.

The concepts introduced in this section are composed in Fig.~\ref{fig:tree_automation}, showing how they can be combined to build an estimation of the \textit{Swarm Automation Level}.

\begin{figure*}[tp]
\centering
  \includegraphics[width=0.90\textwidth,height=0.5\textheight]{./Figures/tree_automation}
  \caption{Metrics for Swarm Automation.}
  \label{fig:tree_automation}
\end{figure*}

\section{Interaction Indicators}

The interaction between the human and swarm refers to the communication approach and the control methods which allow for exchange of their intent information and actions. It is natural that some of the factors that influence the swarm mentioned above would also influence the interaction such as level of autonomy and neglect benevolence. A major challenge in HSI is the escalating complexity that could result from an increase in swarm size and task demands.

As the size of the swarm increases, the human has to monitor and control a larger group with massive number of interactions. For example, the human ability to control the swarm in a supervisory control task would severely be limited with the limited cognitive capacity of human operators~\cite{olsen2004fan}. Unfolding indicators for the effectiveness and efficiency of the interaction is important as both form a detection tool for when more or less automation is needed and as a diagnostic tool to understand the success or otherwise of the team.

In HSI, it is necessary to identify the set of key metrics to represent the quality of the interaction, as well as the ability to predict the effectiveness of the interaction~\cite{crandall2007identifying}. These key metrics can serve as the interaction indicators for an adaptive framework of HSI.

\begin{figure*}[tp]
\centering
\includegraphics[width=0.8\textwidth]{./Figures/HSI_attention}
    \caption{HSI including one single human and a swarm under supervisory-control.}
    \label{fig:interaction_loop}
\end{figure*}

Fig.~\ref{fig:interaction_loop} shows the basic interaction loop for an HSI system.  There are three fundamental metric classes used in HSI introduced in Crandall et al.~\cite{crandall2007identifying}: \textit{interaction efficiency}, \textit{neglect efficiency}, and \textit{attention allocation efficiency}. The efficiency of the interaction is commonly evaluated through interaction efficiency. The bottom loop of figure~\ref{fig:interaction_loop}  describes the entities in the swarm. They sense the environment and produce appropriate actions corresponding to a certain level of autonomy. The efficiency of the entities performing the task without the attention of the human operator is assessed by neglect efficiency. The attention allocation efficiency is a metric class used to capture the efficiency with which the human operator allocates his/her attention among multiple entities. These three metric classes are dependent on one another and also dependent on the level of autonomy that the swarm component possesses.

\textbf{Interaction Efficiency} comprises different metrics discussed in the literature. The most popular one is the \textit{interaction time} which is the amount of time needed for a human to manage one single entity in the swarm~\cite{crandall2005validating}. When dealing with multiple entities in the environment, this metric can be extended to~\cite{kerman2013methods}:
\begin{equation}
    \textit{IEm} = f(N(t))\times \textit{interaction\ \ time},
\end{equation}
where \textit{IEm} is the Interaction Efficiency for multiple entities and $N(t)$ is the number of agents the human interacts with at time $t$. The $f(N(t))$ term denotes a function describing the relationship between the swarm size and the time needed to manage the swarm. In the simplest, case this relationship might be linear in the increase of the number of agents in the swarm: $f(N(t)) = N(t)$.

\textbf{Neglect Efficiency} can be assessed by \textit{neglect tolerance} expressed by the time an agent can be ignored before the error exceeds a threshold~\cite{goodrich2003seven}. The neglect time has a direct relationship to the preservation of acceptable performance. Improving the neglect time is one goal of a successful HRI system, whereby the agent has enough capability to deal with the task. While we discussed neglect tolerance in the automation indicators, we still mention this metric here because it has an indirect impact on reducing the \textit{interaction effort}.

\textbf{Interaction Effort} provides information on how a particular interface design affects the overall effectiveness of the interaction. Interaction effort is defined both physically by the interaction time and cognitively through the cognitive effort~\cite{olsen2003metrics} of subtask choices, information requirement of the new situation after a choice, planning, and intent translation. When interacting with multiple agents, the interaction effort can be estimated indirectly via neglect tolerance and Fan-out (the maximum number of agents the human is able to control effectively):
\begin{equation}
    IEft = \frac{neglect\ \ tolerance}{Fan-out \ \ -\ \ 1},
\end{equation}

\textbf{Attention Allocation Efficiency} includes human's situation awareness of the entire swarm and environment, the switching time and the time the human makes decision on which agent to switch his/her attention to. When a human operates a swarm of multiple entities, the human must neglect some agents and focus his/her attention on controlling one agent. Attention allocation efficiency captures this part of the interaction where attention switching is occurring. 

\textbf{Intervention metrics} are used to estimate the cognitive and physical efforts of human when interacting with an autonomous robot in HRI. Interventions~\cite{huang2003toward}~\cite{steinfeld2006common} are unplanned interactions as opposed to planned interactions in normal modes of operations. The intervention metrics include: the average number of interventions over a time period, the time required for interventions, and the effectiveness of intervention~\cite{scholtz2003evaluation}. The efficiency of the interaction can be also evaluated through the ratio of intervention time to autonomy time~\cite{yanco2004beyond}. For example, if the operator needs one minute to give a navigation instruction to robots, and then the robots complete the navigation task in ten minutes, the ratio is 1:10.

This group of metrics has a strong connection to the level of autonomy that the swarm component possesses. In a shared control situation where there is a possibility for negotiation between human and automation, it is essential to identify extra measures such as the percentage of requests for assistance created by robot, the percentage of requests for assistance created by human, and the number of insignificant interventions of human operator~\cite{steinfeld2006common}.

\textbf{Communication metrics} captures those factors impacting the communication channels between the human and the swarm including latency and bandwidth, especially in the case of teleoperation or remote interaction with a large swarm. The problem of limited bandwidth was mentioned in~\cite{mclurkin2006speaking} in an attempt to design an effective interface for HSI, in which the centralized user interface is responsible for human command broadcasting as well as integrating the information of the whole swarm to visualize them for the human operator. Kolling et al.~\cite{kolling2016human} reported a series of HSI experiments with different bandwidths. The findings supported the claim that the higher bandwidth offered larger capacity for multiple robots\textquoteright  states acquisitions in a time step. An increase in latency caused degradation of interactions~\cite{steinfeld2006common,walker2012neglect}. The problems mentioned above affect the effectiveness and the efficiency of the HSI because they impact the asynchrony of interaction among swarm members and delays in the bidirectional interactions. A solution for these problems can be a predictive display using swarm dynamics and bandwidth information.

The relationship between the interactions metrics discussed above and the effectiveness and efficiency metrics of automation are summarized in Fig.~\ref{fig:tree_interaction}.

\begin{figure*}[tp]
\centering
\includegraphics[width=0.95\textwidth]{./Figures/tree_interaction}
\caption{An example of a set of interaction indicators.}
\label{fig:tree_interaction}
\end{figure*}


\section{Human Cognitive States}
\label{humanSubSection}

Integrating human cognitive states into adaptive systems is a critical step towards effective and efficient HSI for two reasons. First, real-time assessment of human\textquoteright s cognitive states, such as cognitive workload, fatigue and attention, enables the system to adjust itself to maintain the human states within a safe envelope. This is particularly useful in scenarios where human mistakes caused by overload/underload or fatigue could potentially result in hazardous consequences. Second, human cognitive states can be translated into meaningful guidance for adaptation (e.g., swarm level of autonomy). It becomes pertinent to the adaptive HSI system to have a clear understanding of human cognitive states. 

While there is a myriad of studies that rely on subjective metrics for  the estimation of cognitive states, such as NASA-TLX (~\cite{hart1988development}), they are unsuitable for real-time adaptation. There exist several physiological modalities such as Heart rate~\cite{borghini2014measuring}, Electromyography (EMG)~\cite{fallahi2016effects}, functional near infrared (fNIR) spectroscopy~\cite{ayaz2012optical}, Eye-related measures~\cite{marquart2015review}, and electroencephalography (EEG)~\cite{borghini2014measuring} for the objective measurement of human cognitive states. Among the above-mentioned modalities, EEG can be considered as the most practical modality to estimate cognitive states in real-time applications due to its high temporal resolution and high sensitivity to the human\textquoteright s cognitive demands~\cite{borghini2014measuring}. To the best of our knowledge EEG metrics of cognitive states in the context of HSI have not been yet explored. However, fundamental EEG feature sources namely power spectra and event related potentials (ERPs) are context-independent and have been thoroughly investigated in a variety of applications and paradigms. More specific metrics stem from these fundamental sources and their differences arise from a number of variables such as location of  the recording electrodes (e.g. Fz), frequency bands (e.g. theta band), and the type of signal processing measure (e.g. mean of the power spectral density). We discuss the use of currently well-established EEG metrics as the measures of Mental fatigue, workload, and attention.    

\textbf{Mental fatigue:} Zhao et al.~\cite{zhao2012electroencephalogram} demonstrated the effect of mental fatigue on EEG signals. They found that relative power (ratio between the power of each band and the power of total band) in theta band increased in the occipital, frontal and central regions as an effect of fatigue (Note that the relative power in each region was calculated by averaging relative powers of all electrodes in the corresponding region). In addition the relative power of alpha band increased in four regions namely parietal, temporal, central, and occipital. On the other hand, Beta rhythm saw a decrement in the temporal, frontal, and central regions. This work also investigated the effect of mental fatigue on P300 (i.e. ERP). They reported a significant decrease in the amplitude of P300 at Fz and Cz electrodes.

\textbf{Mental workload:} The ratio of theta power at Fz to alpha power at Pz has been shown as a useful mental workload metric that can be used to distinguish between dual-task and single-task performances~\cite{matthews2015psychometrics}. Amplitude of P300 and $\textit{beta}/(\textit{alpha}+\textit{theta})$ as a spectral power metric are also sensitive to the mental workload of the human operator~\cite{isreal1980p300}~\cite{prinzel2003effects}. These two indicators were used to switch between two modes of performing tasks, manual and automated, as well as to explore effectiveness of adaptive autonomy on the task performance~\cite{prinzel2003effects}. In our proposed framework  $\textit{beta}/(\textit{alpha}+\textit{theta})$ and P300 metrics can also be used to change the level of autonomy in multitask scenarios. The former index can be used to adapt the interaction related to the main task (ongoing task), while the latter one can be used to adapt the interaction related to secondary tasks (interrupting tasks).

\textbf{Focused attention:} It was demonstrated that the power of theta band at Fz is associated with the focused attention, and consequently can be used to differentiate between strategies taken by expert and novice shooters~\cite{doppelmayr2008frontal}. 

Fig.~\ref{fig:tree_human2} summarizes the EEG metrics of three cognitive states namely focused attention, mental workload, and fatigue.

\begin{figure*}[tp]
\centering
\includegraphics[width=0.90\textwidth,height=0.5\textheight]{./Figures/tree_human2}
\caption{The human cognitive states indicators.}
\label{fig:tree_human2}
\end{figure*}

\section{Mission Complexity}
\label{complexity}

Mission complexity indicates the overall level of effort needed by both humans and swarm to perform the mission. In a teleoperation scenario, mission complexity is in the hands of a human alone. In a shared control scenario, mission complexity is distributed between the humans and the swarm. In essence, it sits in the hands of the adaptive logic agent to decide how to distribute the functions during function reallocation. In this section, and without loss of generality, we look at this component of mission complexity that is assigned to the human; thus, while the previous section looked at indicators of workload, this section looks at causes of workload; that is, mission complexity. At a zero-level of autonomy, the component assigned to a human is simply the overall mission complexity of the HSI. For a fully autonomous system that does not require any human oversight or interaction, the mission complexity component assigned to the human is zero. Between these two extremes, the component assigned to the human, and therefore influence human workload, is general enough to cover the overall mission complexity concept.

Mission complexity influences the amount of mental workload a mission will potentially require from a human. 
As human workload can negatively hinder the success of a mission that relies on the collaboration between the human and the swarm, the continuous monitoring and adaptation of mission complexity becomes crucial. Although human workload can be measured directly using psycho-physiological techniques as discussed in section~\ref{humanSubSection}, mission complexity is distinct in two ways. First, mission complexity considers only workload associated with the mission, such that if a portion of the workload experienced by a human is related to some factors external to the mission, this portion will not be accounted for by mission complexity. Second, complexity metrics play a diagnostic role by identifying how each task contribute to the overall mission-related workload. This is particularly important to the adaptive agent as it gives the required information on how  a certain adaptation could potentially result in the desirable level of workload.
In this section, we first discuss different factors of complexity and then we show how these factors form the three components of mission complexity.

\subsection{Factors of Complexity}
Both objective and subjective factors can impact the perceived mission complexity by, and therefore performance of, a human~\cite{objectiveSubjective}. Objective factors can stem from task structure, the interface, or the environment, while subjective factors stem human\textquoteright s experience, skills, and self confidence.
The main focus of this section is the objective factors of mission complexity. We will divide these factors into three groups, depending on whether they are caused by the swarm, the interface, or the structure of the mission.

\textbf{Swarm Characteristics: }
Within a team setting, properties of the teammate-- the swarm-- can have a considerable impact on mission complexity. Two basic swarm characteristics have been identified in the literature as affecting human mental workload: level of autonomy and size. 
A swarm level of autonomy was shown to be an important source of complexity. In ~\cite{ruff2002},  Ruff et al. studied the workload associated with different levels of autonomy while navigating a group of four UAVs. They found that manual control resulted in the highest level of workload. Riley et al.~\cite{usarJ} found the same result in robot-assisted search and rescue missions.   Mi et al.~\cite{LOA} also argued that these results generalise to swarm operation, as well. 
However, increasing the level of autonomy as in semi-autonomous swarms doesn\textquoteright t lead to the omission of workload. In principle, this setting requires considerable cognitive resources as the human has to understand a plethora of information arriving from the swarm~\cite{swarmingNetwork} in order to maintain high level of situation awareness.  

The size of the swarm can also result in increasing the workload requirements. Ruff et al.~\cite{ruff2002} found that increasing the number of UAVs results in increasing the perceived workload. Furthermore, this increase is sharp in the case of manual control. However, by providing scalable control methods rather than controlling individual members, the workload can remain constant. For instance, Kolling et al.~\cite{towards} proposed two methods for controlling the swarm in a foraging task: selection and beacon. They showed that the number of human instructions didn\textquoteright t change significantly across different swarm sizes. Pendleton et al.~\cite{scalableHSI} also used three control methods in a foraging task: leader, predator, or stakeholder. They found that using these control methods doesn\textquoteright t result in a significant change in the workload across different swarm sizes.

\textbf{The interface: }
In addition to swarm characteristics, the interface between the team players, the human from one side and the swarm for the other side, can also contribute to mission difficulty. Interface complexity can stem from the activated swarm control method, the information presented, and the display technology used. Irrespective of the level of autonomy of the swarm and the number of swarm members, the active control method can affect the complexity of the interface. For example, Pendleton~\cite{scalableHSI} found that both control by a leader and a stakeholder results in a lower workload than control by a predator. 

Information presentation decisions with respect to the amount  and level of information presented are another source of interface complexity. The amount of information affects cognitive load such that too little information results in increasing uncertainty and leads humans to integrate information from other sources like their own assumptions, which could result in an increase in cognitive load~\cite{lost}. Too much information, on the other hand, causes information overload and makes the human overwhelmed with a large amount of information that may exceed their cognitive capacity. The impact of the level of information was also examined by previous works. Van der Land et al.~\cite{SAChapter} argued that low-level information negatively impacts operators\textquoteright  cognitive load as they have to process it to build higher levels of SA~\cite{SAPerformance}. 

The choice of the display technology may have implications on SA and workload. Ruiz et al.~\cite{immersive} compared the use of different display technologies in multi-UAV operations. They found that virtual reality (VR) based immersive screen results in the best operator\textquoteright s SA and the lowest cognitive load. Besides, they found that VR glasses outperform standard screen in terms of improving SA, yet this improvement comes at the cost of increasing workload.

\textbf{Task structure: }
The structure of the mission and how it is executed is a third source of complexity. For instance, the existence of tasks that are executed concurrently adds to the human workload. Liu et al.~\cite{complexity2012} pointed out that task concurrency  leads to higher mission complexity by increasing the information load. Chen and Barnes~\cite{HATeaming} argued that switching between tasks can increase workload as there can be interference between task related information. This interference increases if tasks are similar with respect to stimuli, processing stages, or required responses~\cite{Caroline}. It has been found that humans may need long time (up to 7 seconds) to recover task related SA~\cite{HATeaming}.

\subsection{Components of Complexity}
Throughout the mission, a human can be involved in three types of activities: action execution, SA formation, or SA restoration. These classes of activities will be considered the main components that constitute mission complexity. 
%\begin{equation}
%Complexity= w_1* Action\_Execution\_Complexity
%\end{equation}

\textbf{Action Execution: }
The number of actions a human needs to perform depends on the level of autonomy of the swarm, the control method, and the size of the swarm. 
At low levels of autonomy, the human has to execute different a variety of actions at both low and high levels, e.g, way-point navigation and target identification respectively. As level of autonomy increases, a human becomes mainly responsible for mission-level tasks while the swarm takes over those of low level. 
The scalability of a control method used will determine how frequent a certain type of action needs  to be performed in relation to the number of swarm members. 
For instance, the task of identifying regions of interest in the environment will be performed a fixed number of times. 
However, identifying targets found by each swarm member will be repeated a number of times proportional to the number of swarm members. 
Thus, the total number of actions a human needs to perform will be the product of types of different actions, multiplied by the frequency of executing each type of action. 

\textbf{SA Formation: }
While supervising the swarm within a mission, the human needs to attend to and integrate the incoming information to acquire the SA. The complexity of SA formation comes from the amount and level of information presented as well as the display technology used. 
As the amount of information increases, the human will need to exert more effort to perceive these pieces of information. For example, presenting the health level of each swarm member can be more mentally demanding than presenting the average and standard deviation of the health of the swarm as a whole.  
Moreover, if the information is presented in a primitive form, the human needs to integrate it with  previous pieces of information to understand how the state changes and to be able to make predictions. 
Lastly, the display technology used can decrease the mental workload required particularly for tasks requiring high spatial skills.

\textbf{SA Restoration: }
As the number of concurrent tasks and interruptions increases, the human will more often need to leave a certain task for a while to execute other tasks or respond to active interruptions.
When switching back to the old task, a human needs to exert effort to restore the SA of the task and to catch up any updates that took place while executing other tasks. 
The difficulty of restoring the SA will increase as the similarity between the tasks increase due to possible interference. 
Thus, the complexity for restoring SA is function of both the number of concurrent tasks and the similarity between tasks.

The concepts introduced in this section are composed in Fig.~\ref{fig:tree_complexity}, showing how they can be combined to build an estimation of the \textit{Mission Complexity}.
\begin{figure*}[tp]
\centering
\includegraphics[width=0.90\textwidth,height=0.4\textheight]{./Figures/tree_complexity}
\caption{Components of mission complexity.}
\label{fig:tree_complexity}
\end{figure*}

\section{All in One: The MICAH Framework}
\label{implications}

In the previous sections, we presented the five types of indicators that need to be brought together for the adaptive logic AI agent to manage the interaction in HSI systems. 
The context the HSI system is operating within may necessitate replacing and/or augmenting the particular metrics we discussed.
Nevertheless, all five types are necessary and the interdependencies among them need to be clearly defined to ensure an effective design of the adaptive logic AI agent. 
We named this framework with the acronym \textit{MICAH}, and a visual summary of it is presented in Fig.~\ref{fig:MICAH}.
\begin{figure}[tp]
\centering
\includegraphics[width=0.48\textwidth]{./Figures/MICAH}
\caption{MICAH: categories of indicators used for adaptation in HST}
\label{fig:MICAH}
\end{figure}
The five types of indicators can be summarized in the following way with the letter contributing to the abbreviation MICAH underlined:

\begin{itemize}
  \item \underline{M}ission Performance: composed of effectiveness and efficiency, it is the primary objective of the system and should never be disregarded;

  \item \underline{I}nteraction: describes how productive the interaction between the human and the swarm is; monitoring this indicator gives insight into the current interaction mode;

  \item Mission \underline{C}omplexity: studies how the task, interface and swarm contribute to the workload for the human; it is an important factor in determining the performance of the human and the complexity of the mission at a particular point of time to trigger appropriate level of automation;

  \item \underline{A}utomation level: analyzes the performance of the swarm and its need for human intervention, which are fundamental inputs to correctly set the level of autonomy;

  \item \underline{H}uman cognitive states: assesses the mental conditions of the human, determining for example if they are overloaded or underloaded and allowing the system to adapt accordingly
\end{itemize}

The main purpose of MICAH is being a synthesis of indicators needed to design adaptive HSI systems. A practical system does not need to use the exact indicators described in this paper, but the five components should all be considered by the adaptation manager.

Revisiting the scenario in section~\ref{scenario}, the state assessment of the five components can indicate high collection rate, effective interaction and well-performing swarm, while the workload on the human is within the acceptable region. 
This assessment means that the current setting is appropriate and doesn\textquoteright t need interventions from the adaptive logic AI agent, yet the monitoring is to be continued so that changes in the indicators can be captured. 
Another assessment can, however, signal the need for adaptation. 
For instance, with low collection rate, low workload levels on the human, and effective interaction, assigning more tasks to the human can benefit the mission. 
On the other hand, with low rate of target collection, high workload on the human, and swarm with high dependence on the human, two different cause roots for this problem may exist.
One could be that the capabilities of the swarm  are inferior to the requirements of the task.
The second could be that the human doesn\textquoteright t have the required set of skills. 
Complexity indicators could provide the needed diagnostic information; such that high levels of task complexity means the swarm is the cause of the problem while moderate-to-low levels of task complexity refers to the human as the cause of the problem.

\section{Conclusion}\label{conclusion}
In this paper, we proposed a framework that extends existing concepts of adaptive systems, to fit swarm systems in order to achieve effective and efficient HSI. We brought together literature from different fields including HRI, HSI, task complexity, and psycho-physiological techniques to identify and discuss classes of indicators that convey complementary information that are significant for effective adaptive autonomy.

The adaptive logic AI agent has two phases: monitoring and assessment, and adaptation.
We focused this paper on the first phase. 
The mapping from state assessment to a certain adaptation is by no means trivial and will be the focus of our future extension of this work where we will aim at designing the technical details of the adaptation systems based on the proposed framework. 
 
\section*{Acknowledgement}
This research was funded by the Australian Research Council grant number DP160102037.

\bibliographystyle{IEEEtran}
\bibliography{HST}

\begin{IEEEbiography}[{\includegraphics[width=0.9in,height=1.2in,clip]{./Figures/Aya}}]{Aya Hussein} is pursuing a PhD at the University of New South Wales, Canberra, Australia. She received her Bachelors and Masters degrees in Computer Engineering from Cairo University, Egypt, in 2011 and 2015. Her research interests include Human-Machine Interaction, Human Factors, Natural Language Processing, and Machine Learning.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=0.9in,height=1.1in,clip]{./Figures/leo}}]{Leo Ghignone} is pursuing a PhD at the University of New South Wales, Canberra, Australia. He received his Bachelor and Masters degrees in Computer Science from the University of Turin, Italy, with a focus on Artificial Intelligence and Machine Learning. His current research is directed towards Swarm Intelligence to develop Machine Learning algorithms that can manage the particular qualities and requirements of swarms and make them more approachable for humans.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=0.9in,height=1.1in,clip]{./Figures/Tung}}]{Tung Nguyen} is pursuing a PhD at the University of New South Wales, Canberra, Australia. He received his B.Eng. degree in Biomedical Engineering from Hanoi University of Science and Technology, Vietnam in 2015 and his MSc in Computer Science from University of New South Wales - Canberra in 2018. His research interests include deep learning, reinforcement learning, agent architecture, trusted autonomous systems and human-machine teaming.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=0.9in,height=1.1in,clip]{./Figures/Nima}}]{Nima Salimi}  is pursuing a PhD at the University of New South Wales, Canberra, Australia. He received a M.E. degree in biomedical engineering from the University of Malaya, Malaysia, and a B.E. degree in electrical and electronic engineering from the Islamic Azad University, Iran. His research interests include, computational neuroscience, EEG signal processing, and human-swarm interaction.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=0.9in,height=1.1in,clip]{./Figures/Hung}}]{Hung Nguyen} is pursuing a PhD at the University of New South Wales, Canberra, Australia. He received his B.E degree in Information Technology from Military Technical Academy, Vietnam in 2010 and his MSc in Computer Science from University of New South Wales - Canberra in 2018. His current research involves apprenticeship bootstrapping, deep learning, reinforcement learning, imitation learning, unmanned aerial and ground vehicles coordination systems and human-machine teaming. 
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=0.9in,height=1.1in,clip]{./Figures/MinWang}}]{Min Wang} is pursuing a PhD at the University of New South Wales, Canberra, Australia. She received her M.Sc. degree in signal processing in 2015 from the Faculty of Information Science and Engineering, Ocean University of China, Qingdao, China. Her research interests include nonlinear time-series analysis, biomedical signal processing, pattern recognition, deep learning and human-machine interaction.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./Figures/hussein}}]{Hussein A. Abbass} is a Professor in the School of Engineering and Information Technology, at the University of New South Wales - Canberra. He has been a member of HFES since 2014. Hussein is an associate Editor of the IEEE TRANSACTIONS ON CYBERNETICS, IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS, IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS, and four other journals. His current research contributes to trusted autonomy with a focus on human-swarm interaction. His work fuses artificial intelligence, cognitive engineering, brain computer interfaces, and robotics. 
\end{IEEEbiography}
\end{document}
